================================================================================
RKL SECURE REASONING BRIEF - RECORDING TRANSCRIPT
Recording Date: November 25, 2025
Target Duration: 3:00-3:10 (180-190 seconds)
Recording Strategy: Section-by-section (2-take maximum per section)
================================================================================

INSTRUCTIONS FOR RECORDING:
- Record each section separately (01-opening.wav, 02-problem.wav, etc.)
- Take up to 2 takes per section maximum
- Leave 2 seconds of silence before/after each take
- Don't edit as you go - save all editing for laptop later
- Speak clearly at moderate pace (not rushed)
- Emphasize key phrases: "Type III", "provable", "honest prototype"

================================================================================

===== SECTION 1: OPENING (50 seconds) =====
File: 01-opening.wav

Hi, I'm Mike Brady. I work with protected research data that can't leave local infrastructure, but I want to leverage powerful cloud AI models - and I thought others might face this challenge too.

For the Kaggle AI Agents Capstone, I built an 18-agent system demonstrating Type III Secure Reasoning - a framework I developed where raw data stays local, but derived insights can be reasoned over by cloud AI. It monitors AI safety papers and generates automated daily briefs and weekly blogs written by Gemini.

I'm using public article data as a proxy to demonstrate the architecture I need for actual sensitive data.

Full transparency: I used AI coding assistants - Claude Code and ChatGPT - to scaffold the implementation. I designed the architecture and workflows; AI helped me build it faster than I could alone.

================================================================================

===== SECTION 2: PROBLEM & SOLUTION (15 seconds) =====
File: 02-problem.wav

To demonstrate this architecture, I built something I actually need: an AI safety research monitor.

The challenge: hundreds of papers weekly make it hard to track critical insights, especially advances in secure reasoning approaches.

The solution: Automated daily briefs and weekly analysis. Every step generates telemetry proving Type III compliance - local processing for raw content, cloud reasoning for synthesis.

================================================================================

===== SECTION 3: ARCHITECTURE OVERVIEW (25 seconds) =====
File: 03-architecture.wav

The architecture uses 18 agents across four phases. Discovery and processing happen locally with Ollama - raw papers never leave the system. Quality analysis and publication use Gemini, but it only sees summaries of the raw data. This is Type III in action - sensitive data never leaves the local system, but cloud AI still powers the reasoning.


================================================================================

===== SECTION 4: DEMO - DAILY BRIEF (20 seconds) =====
File: 04-daily-brief.wav

The system runs twice daily. Each run processes up to 20 papers and produces a brief you can read in 2-3 minutes. Here's today's morning brief showing the structure: headline findings, must-read papers with practical insights, and patterns worth tracking.


================================================================================

===== SECTION 5: DEMO - WEEKLY SYNTHESIS (20 seconds) =====
File: 05-weekly-synthesis.wav

Every Sunday, the system generates a comprehensive weekly blog synthesizing the full week of papers. Gemini writes this seeing only summaries - never raw article text. This proves the Type III boundary works: cloud AI produces quality analysis without accessing the raw source data - proving the pattern works for sensitive data scenarios.

================================================================================

===== SECTION 6: TELEMETRY PROOF (25 seconds) =====
File: 06-telemetry.wav

We prove Type III compliance using telemetry. Every agent logs what data it processed and whether raw data crossed the boundary. The governance ledger provides explicit verification at each step. This isn't just logging - it's machine-readable proof that data boundaries were maintained throughout the pipeline.


================================================================================

===== SECTION 7: REAL-WORLD IMPACT (15 seconds) =====
File: 07-impact.wav

This system runs in production fully automated via cron, processing hundreds of papers weekly into daily briefs and comprehensive weekly analysis. It's useful for tracking AI safety research, and it begins to show how the Type III pattern may work for real-world sensitive data scenarios.

================================================================================

===== SECTION 8: CLOSING (20 seconds) =====
File: 08-closing.wav

This project demonstrates Type III Secure Reasoning: local processing for raw data, cloud AI for derived insights, with telemetry proving the boundaries held. It's a working system that aims to solve a real problem, and it shows a pattern that could apply wherever sensitive data meets powerful AI.

The code, white paper, and dataset are all available in the submission. Thanks for watching.

================================================================================

TOTAL ESTIMATED DURATION: ~190 seconds (3:10)
RECORDING FILES: 8 separate WAV files (01-opening.wav through 08-closing.wav)

================================================================================
END OF TRANSCRIPT
================================================================================
