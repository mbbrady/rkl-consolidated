# Ollama Configuration
# Use head node (serv) for cluster deployment: http://192.168.1.10:11434/api/generate
# Use localhost for local testing: http://localhost:11434/api/generate
OLLAMA_ENDPOINT=http://192.168.1.10:11434/api/generate
OLLAMA_MODEL=llama3.2

# Brief Configuration
BRIEF_MAX_ARTICLES=20
BRIEF_SUMMARY_MAX_WORDS=80

# Publishing Configuration
PUBLISH_TO_GITHUB=false    # Set to true to auto-commit briefs
AUTO_PUSH=false             # Set to true to auto-push to remote (triggers Netlify deploy)

# Logging
LOG_LEVEL=INFO
LOG_FILE=./logs/agent.log
